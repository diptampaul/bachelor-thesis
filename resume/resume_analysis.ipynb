{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import spacy\r\n",
    "from spacy.training.example import Example\r\n",
    "import pickle\r\n",
    "import random"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\dipta\\appdata\\roaming\\python\\python39\\site-packages (3.1.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\python39\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dipta\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python39\\lib\\site-packages (from spacy) (4.62.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python39\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\python39\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\python39\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\python39\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\python39\\lib\\site-packages (from spacy) (8.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\python39\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python39\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\python39\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\python39\\lib\\site-packages (from spacy) (1.19.4)\n",
      "Requirement already satisfied: setuptools in c:\\python39\\lib\\site-packages (from spacy) (49.2.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python39\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\python39\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dipta\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python39\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\python39\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\python39\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\python39\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\python39\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python39\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36940/1137876089.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install spacy --user'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_data = pickle.load(open('train_data.pkl', 'rb'))\r\n",
    "train_data"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36940/1350779564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "nlp = spacy.blank('en')\r\n",
    "\r\n",
    "def train_model(train_data):\r\n",
    "    if 'ner' not in nlp.pipe_names:\r\n",
    "        ner = nlp.create_pipe('ner')\r\n",
    "        nlp.add_pipe('ner', last=True)\r\n",
    "    for _, annotation in train_data:\r\n",
    "        for ent in annotation['entities']:\r\n",
    "            ner.add_label(ent[2])\r\n",
    "\r\n",
    "    #Prepare the data\r\n",
    "\r\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\r\n",
    "    with nlp.disable_pipes(*other_pipes):     #Only train NER\r\n",
    "        optimizer = nlp.begin_training()\r\n",
    "        for itn in range(10):\r\n",
    "            print(\"Starting iteration \"+str(itn))\r\n",
    "            random.shuffle(train_data)\r\n",
    "            losses = {}\r\n",
    "            index = 0\r\n",
    "\r\n",
    "            \r\n",
    "            for text, annotation in train_data:\r\n",
    "                try:\r\n",
    "                    doc = nlp.make_doc(text)\r\n",
    "                    example = Example.from_dict(doc, annotation)\r\n",
    "                    nlp.update(\r\n",
    "                        [example],   #batch of Example objects\r\n",
    "                        drop = 0.2,\r\n",
    "                        sgd = optimizer,\r\n",
    "                        losses = losses\r\n",
    "                    )\r\n",
    "                #     nlp.update(\r\n",
    "                #         [text],   #Batch of texts\r\n",
    "                #         [annotation],   #Batch of annotations\r\n",
    "                #         drop = 0.2,\r\n",
    "                #         sgd = optimizer,\r\n",
    "                #         losses = losses\r\n",
    "                #     )\r\n",
    "                except Exception as e:\r\n",
    "                    #print(e)\r\n",
    "                    pass\r\n",
    "                \r\n",
    "            print('losses')\r\n",
    "            print(losses)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "#Training the model\r\n",
    "train_model(train_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting iteration 0\n",
      "losses\n",
      "{'ner': 10057.4903923769}\n",
      "Starting iteration 1\n",
      "losses\n",
      "{'ner': 4319.248714557079}\n",
      "Starting iteration 2\n",
      "losses\n",
      "{'ner': 2544.4841815113823}\n",
      "Starting iteration 3\n",
      "losses\n",
      "{'ner': 2146.6085002281175}\n",
      "Starting iteration 4\n",
      "losses\n",
      "{'ner': 1900.3484439596375}\n",
      "Starting iteration 5\n",
      "losses\n",
      "{'ner': 1751.7195115033749}\n",
      "Starting iteration 6\n",
      "losses\n",
      "{'ner': 1599.9575738060448}\n",
      "Starting iteration 7\n",
      "losses\n",
      "{'ner': 1563.4968174207386}\n",
      "Starting iteration 8\n",
      "losses\n",
      "{'ner': 1286.2523714916606}\n",
      "Starting iteration 9\n",
      "losses\n",
      "{'ner': 1239.8304078584551}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "#Storing the trained NLP model\r\n",
    "\r\n",
    "nlp.to_disk('nlp_model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "#Load the trained nlp model\r\n",
    "nlp_model = spacy.load('nlp_model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "train_data[0][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Mohini Gupta Server Support Engineer  Gurgaon, Haryana - Email me on Indeed: indeed.com/r/Mohini-Gupta/08b5b8e1acd8cf07  Willing to relocate: Anywhere  WORK EXPERIENCE  Server Support Engineer  Microsoft -  July 2015 to November 2017  Key Responsibilities: ● Worked as Technical Support Engineer for Microsoft Enterprise Platforms Support.  ● Worked in U.S., U.K., India & APAC time zones.  ● Always available (24X7) for any explanation, support or information required by team, client and managers.  ● Configuring, deploying and troubleshooting SCCM with remote/local SQL. ● Perform Software distribution and ensure successful deployment on end assets. ● Patch management of servers and end user estate along with troubleshooting. ● Performed on checks through server, to perform server operations, check services, analyzed the logs to check the communication from the new server to the primary server and vice versa, also checked server's communication with its client. ● Setting up new packages along with new collection. ● Collection of inventory i.e. hardware inventory and software inventory. ● Troubleshooting client connectivity and package installation issues by analysis of logs. ● Working on incidents logged by end users as a daily activity. ● Fixing operational issues and performing installation or un-installation of applications. ● Create new groups, add users and grant permissions. ● Good understanding of SCCM architecture, operations and management. ● Knowledge of Active Directory and networking required in SCCM environment. ● Deploying Operating System with SCCM.  Server Support Engg.  Convergys -  July 2015 to November 2017  Server Support Engg.  EDUCATION  B.tech  https://www.indeed.com/r/Mohini-Gupta/08b5b8e1acd8cf07?isid=rex-download&ikw=download-top&co=IN   KIIT college of Engg.  SKILLS  active directory, iis, sccm, dhcp, sql, wsus, dns  ADDITIONAL INFORMATION  Computer Skills ● MS Office Tools: MS Excel, MS Word, MS Power Point. ● Hands on experience on all versions of Windows. ● Sound knowledge of internet and networking. ● Coding Languages: C, C++, Java.  Other Information ● Regular Swimmer. ● Interested in playing Table Tennis, Lawn Tennis. ● Professional Proficiency: English and Hindi  I hereby declare that all the above particulars are true to the best of my knowledge.  PLACE: Gurgaon (MOHINI GUPTA)\""
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "doc = nlp_model(train_data[0][0])\r\n",
    "for ent in doc.ents:\r\n",
    "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NAME                          - Mohini Gupta\n",
      "DESIGNATION                   - Server Support Engineer\n",
      "EMAIL ADDRESS                 - indeed.com/r/Mohini-Gupta/08b5b8e1acd8cf07\n",
      "DESIGNATION                   - Server Support Engineer\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "DEGREE                        - B.tech\n",
      "COLLEGE NAME                  - KIIT college of Engg.\n",
      "SKILLS                        - active directory, iis, sccm, dhcp, sql, wsus, dns  ADDITIONAL INFORMATION  Computer Skills ● MS Office Tools: MS Excel, MS Word, MS Power Point. ● Hands on experience on all versions of Windows. ● Sound knowledge of internet and networking. ● Coding Languages: C, C++, Java.\n",
      "LOCATION                      - Gurgaon\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now run the test resumes to check whether it is working or not"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Convert PDF to text using PyMuPDF, as PyPDF2 does not work properly\r\n",
    "import sys\r\n",
    "import fitz\r\n",
    "fname = \"Smith Resume.pdf\"\r\n",
    "doc = fitz.open(fname)\r\n",
    "text = \"\"\r\n",
    "for page in doc:\r\n",
    "    text = text + str(page.getText())\r\n",
    "\r\n",
    "print(text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Michael Smith \n",
      "BI / Big Data/ Azure \n",
      "Manchester, UK- Email me on Indeed: indeed.com/r/falicent/140749dace5dc26f \n",
      " \n",
      "10+ years of Experience in Designing, Development, Administration, Analysis, \n",
      "Management \n",
      "inthe \n",
      "Business \n",
      "Intelligence \n",
      "Data \n",
      "warehousing, \n",
      "Client \n",
      "Server \n",
      "Technologies, Web-based Applications, cloud solutions and Databases. \n",
      "Data warehouse: Data analysis, star/ snow flake schema data modeling and design \n",
      "specific todata warehousing and business intelligence environment. \n",
      "Database: Experience in database designing, scalability, back-up and recovery, \n",
      "writing andoptimizing SQL code and Stored Procedures, creating functions, views, \n",
      "triggers and indexes.  \n",
      "Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL \n",
      "Azure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure \n",
      "data lake analytics(U-SQL). \n",
      "Big Data: Worked Azure data lake store/analytics for big data processing and Azure \n",
      "data factoryto schedule U-SQL jobs. Designed and developed end to end big data \n",
      "solution for data insights.  \n",
      " \n",
      "Willing to relocate: Anywhere \n",
      "WORK EXPERIENCESoftware Engineer \n",
      "Microsoft - Manchester, UK. \n",
      "December 2015 to Present \n",
      "1. Microsoft Rewards Live dashboards: \n",
      "Description: - Microsoft rewards is loyalty program that rewards Users for \n",
      "browsing and shopping online. Microsoft Rewards members can earn points when \n",
      "searching with Bing, browsing with Microsoft Edge and making purchases at the \n",
      "Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up \n",
      "bonus points for taking daily quizzes and tours on the Microsoft rewards website. \n",
      "Rewards live dashboards gives a live picture of usage world-wide and by markets \n",
      "like US, Canada, Australia, new user registration count, top/bottom performing \n",
      "rewards offers, orders stats and weekly trends of user activities, orders and new \n",
      "user registrations. the PBI tiles gets refreshed in different frequencies starting \n",
      "from 5 seconds to 30 minutes. \n",
      "Technology/Tools used \n",
      "Event hub, stream analytics and Power BI. \n",
      "Responsibilities \n",
      "Created stream analytics jobs to process event hub data \n",
      "Created Power BI live dashboard to show live usage traffic, weekly trends, cards, \n",
      "charts to showtop/bottom 10 offers and usage metrics. \n",
      "2. Microsoft Rewards Data Insights: \n",
      "Description: - Microsoft rewards is loyalty program that rewards Users for \n",
      "browsing and shopping online. Microsoft Rewards members can earn points when \n",
      "searching with Bing, browsing with Microsoft Edge and making purchases at the \n",
      "Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up \n",
      "bonus points for taking daily quizzes and tours on the Microsoft rewards website. \n",
      "Rewards data insights is data analytics and reporting platform, processes 20 \n",
      "million users daily activities and redemption across different markets like US, \n",
      "Canada, Australia. \n",
      "Technology/Tools used \n",
      "Cosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI. \n",
      "Responsibilities \n",
      "Created big data scripts in cosmos \n",
      "C# data extractors, processors and reducers for data transformation \n",
      "Power BI dashboards \n",
      "3. End to end tracking Tool: \n",
      "Description: - This is real-time Tracking tool to track different business \n",
      "transactions like order, order response, functional acknowledgement, invoice \n",
      "flowing inside ICOE. It gives flexibility to customers to track their transactions \n",
      "and appropriate error information in-case of any failure. Based on resource based \n",
      "access control the tool gives flexibility to end user to perform different actions \n",
      "like view transactions, search based on different filter criteria and view and \n",
      "download actual message payload. End to end tracking tool stitches all the \n",
      "business transaction like order to cash flow and connects different hops inside \n",
      "ICOE like gateway, routing server, Processing server. It also connects different \n",
      "systems like ICOE, partner end point and SAP. \n",
      "Technology/Tools used \n",
      "Azure Document db, Azure web job and Web APP, RBAC, Angular JS. \n",
      "Responsibilities \n",
      "Document dB stored procedures. \n",
      "Web job to process event hub data and populate Document db• Web App API. \n",
      "Stream analytics job to transform data \n",
      "Power BI reports \n",
      "4. Biztrack Tracking Tool: \n",
      "Description: - This is real-time Tracking tool to track different business \n",
      "transactions like order, order response, functional acknowledgement, invoice \n",
      "flowing inside ICOE. It gives flexibility to customers to track their transactions \n",
      "and appropriate error information in-case of any failure. Based on resource based \n",
      "access control the tool gives flexibility to end user to perform different actions \n",
      "like view transactions, search based on different filter criteria and view and \n",
      "download actual message payload. \n",
      "Technology/Tools used \n",
      "SQL server 2014, SSIS, .net API, Angular JS. \n",
      "Responsibilities \n",
      "ETL solution to transform business transactions data stored in Biztalk tables. \n",
      "SQL azure tables, stored procedures, User defined functions. \n",
      "Performance tuning. \n",
      "Web API enhancements. \n",
      " \n",
      "EDUCATION \n",
      "The University of Manchester - UK \n",
      "2007 \n",
      " \n",
      "SKILLS \n",
      "problem solving (Less than 1 year), project lifecycle (Less than 1 year), project \n",
      "manager (Less than 1 year), technical assistance. (Less than 1 year) \n",
      "ADDITIONAL INFORMATION \n",
      "Professional Skills \n",
      "Excellent analytical, problem solving, communication, knowledge transfer and \n",
      "interpersonalskills with ability to interact with individuals at all the levels \n",
      "Quick learner and maintains cordial relationship with project manager and team \n",
      "members andgood performer both in team and independent job environments \n",
      "Positive attitude towards superiors &amp; peers \n",
      "Supervised junior developers throughout project lifecycle and provided technical \n",
      "assistance. \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "#Modifing the extracted text\r\n",
    "tx = \" \".join(text.split('\\n'))   #New line will replaced with black space\r\n",
    "tx"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Michael Smith  BI / Big Data/ Azure  Manchester, UK- Email me on Indeed: indeed.com/r/falicent/140749dace5dc26f    10+ years of Experience in Designing, Development, Administration, Analysis,  Management  inthe  Business  Intelligence  Data  warehousing,  Client  Server  Technologies, Web-based Applications, cloud solutions and Databases.  Data warehouse: Data analysis, star/ snow flake schema data modeling and design  specific todata warehousing and business intelligence environment.  Database: Experience in database designing, scalability, back-up and recovery,  writing andoptimizing SQL code and Stored Procedures, creating functions, views,  triggers and indexes.   Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL  Azure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure  data lake analytics(U-SQL).  Big Data: Worked Azure data lake store/analytics for big data processing and Azure  data factoryto schedule U-SQL jobs. Designed and developed end to end big data  solution for data insights.     Willing to relocate: Anywhere  WORK EXPERIENCESoftware Engineer  Microsoft - Manchester, UK.  December 2015 to Present  1. Microsoft Rewards Live dashboards:  Description: - Microsoft rewards is loyalty program that rewards Users for  browsing and shopping online. Microsoft Rewards members can earn points when  searching with Bing, browsing with Microsoft Edge and making purchases at the  Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up  bonus points for taking daily quizzes and tours on the Microsoft rewards website.  Rewards live dashboards gives a live picture of usage world-wide and by markets  like US, Canada, Australia, new user registration count, top/bottom performing  rewards offers, orders stats and weekly trends of user activities, orders and new  user registrations. the PBI tiles gets refreshed in different frequencies starting  from 5 seconds to 30 minutes.  Technology/Tools used  Event hub, stream analytics and Power BI.  Responsibilities  Created stream analytics jobs to process event hub data  Created Power BI live dashboard to show live usage traffic, weekly trends, cards,  charts to showtop/bottom 10 offers and usage metrics.  2. Microsoft Rewards Data Insights:  Description: - Microsoft rewards is loyalty program that rewards Users for  browsing and shopping online. Microsoft Rewards members can earn points when  searching with Bing, browsing with Microsoft Edge and making purchases at the  Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up  bonus points for taking daily quizzes and tours on the Microsoft rewards website.  Rewards data insights is data analytics and reporting platform, processes 20  million users daily activities and redemption across different markets like US,  Canada, Australia.  Technology/Tools used  Cosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI.  Responsibilities  Created big data scripts in cosmos  C# data extractors, processors and reducers for data transformation  Power BI dashboards  3. End to end tracking Tool:  Description: - This is real-time Tracking tool to track different business  transactions like order, order response, functional acknowledgement, invoice  flowing inside ICOE. It gives flexibility to customers to track their transactions  and appropriate error information in-case of any failure. Based on resource based  access control the tool gives flexibility to end user to perform different actions  like view transactions, search based on different filter criteria and view and  download actual message payload. End to end tracking tool stitches all the  business transaction like order to cash flow and connects different hops inside  ICOE like gateway, routing server, Processing server. It also connects different  systems like ICOE, partner end point and SAP.  Technology/Tools used  Azure Document db, Azure web job and Web APP, RBAC, Angular JS.  Responsibilities  Document dB stored procedures.  Web job to process event hub data and populate Document db• Web App API.  Stream analytics job to transform data  Power BI reports  4. Biztrack Tracking Tool:  Description: - This is real-time Tracking tool to track different business  transactions like order, order response, functional acknowledgement, invoice  flowing inside ICOE. It gives flexibility to customers to track their transactions  and appropriate error information in-case of any failure. Based on resource based  access control the tool gives flexibility to end user to perform different actions  like view transactions, search based on different filter criteria and view and  download actual message payload.  Technology/Tools used  SQL server 2014, SSIS, .net API, Angular JS.  Responsibilities  ETL solution to transform business transactions data stored in Biztalk tables.  SQL azure tables, stored procedures, User defined functions.  Performance tuning.  Web API enhancements.    EDUCATION  The University of Manchester - UK  2007    SKILLS  problem solving (Less than 1 year), project lifecycle (Less than 1 year), project  manager (Less than 1 year), technical assistance. (Less than 1 year)  ADDITIONAL INFORMATION  Professional Skills  Excellent analytical, problem solving, communication, knowledge transfer and  interpersonalskills with ability to interact with individuals at all the levels  Quick learner and maintains cordial relationship with project manager and team  members andgood performer both in team and independent job environments  Positive attitude towards superiors &amp; peers  Supervised junior developers throughout project lifecycle and provided technical  assistance.  '"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "doc = nlp_model(tx)\r\n",
    "for ent in doc.ents:\r\n",
    "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NAME                          - Michael Smith\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COLLEGE NAME                  - The University of Manchester\n",
      "SKILLS                        - problem solving (Less than 1 year), project lifecycle (Less than 1 year), project  manager (Less than 1 year), technical assistance. (Less than 1 year)  ADDITIONAL INFORMATION  Professional Skills\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "d589e7fd2fb751d1d4d4f85efad069be063ceb642c6be1863d2da75aa5789060"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}